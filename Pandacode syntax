import pandas as pd #import pandas 


You've seen the four most common types of data manipulation: sorting rows, subsetting columns, subsetting rows, and adding new columns.
In a real-life data analysis, you can mix and match these four manipulations to answer a multitude of questions.
df.head() >> return the first few rows in the dataframe 
----------------------------------------------------------------
df.info()

- display the name of the columns 
- datatypes 
- whether they have a missing values 
----------------------------------------------------------------
df.shape 

- this is an attribute not a method 
- return a tuple of ( num of rows , num of columns ) 
-----------------------------------------------------------------
df.describe() 
- return summary statistics of numeric data 
- mean - median - count - std - 5 num summary
-----------------------------------------------------------------
dataframe has a 3 main components 

df.values: A two-dimensional NumPy array of values.
df.columns: An index of columns: the column names.
df.index: An index for the rows: either row numbers or row names.
-----------------------------------------------------------------
df.sort_values( column_name ) : to sort the dataframe by this columns 
df.sort_values( column_name , ascending = True / False ) : ascending > False : descending order 
df.sort_values( [ list of columns ] ) : to sort by multiple columns 
df.sort_values( [ list of columns ] , ascending = [ True , False .... ] ) 
-----------------------------------------------------------------------
df['column_name'] : to zoom in one column
df[ [ 'c1' , 'c2' ,,,, ] ] : to zoom in multiple columns 
------------------------------------------------------------------------
Subset the rows 

1) logical conditions 

df [ df [ 'column_name' ] > n ] 

date format : '2016-07-25' year - month - day 

2) using and / or 

df [ (df['column'] > n) & (df['c_name'] < n2)] 
- you need to add () for each conditions 


3) isin : isin method used to filter on multiple values of categorical values 

df['column'].isin([ list of values to filter in]) 

Subsetting data based on a categorical variable often involves using the "or" operator (|) to select rows from multiple categories. This can get tedious when you want all states in one of three different regions, for example. Instead, use the .isin() method, which will allow you to tackle this problem by writing one condition instead of three separate ones.

colors = ["brown", "black", "tan"]
condition = dogs["color"].isin(colors)
dogs[condition]

Using .isin() makes subsetting categorical variables a breeze.
----------------------------------------------------------------------------

Add a new columns to the dataframe 
1) mutating dataframe 
2) transforming dataframe 
3) feature engineering 

You can create new columns from scratch, but it is also common to derive them from other columns, for example, by adding columns together or by changing their units.



df['new_column'] = calculations to create the new columns 
---------------------------------------------------------------------------------
ğ’ğ®ğ¦ğ¦ğšğ«ğ² ğ¬ğ­ğšğ­ğ¢ğ¬ğ­ğ¢ğœğ¬

ğ’ğ®ğ¦ğ¦ğšğ«ğ² ğ¬ğ­ğšğ­ğ¢ğ¬ğ­ğ¢ğœğ¬: a num that summarize and tell you about your dataset 

df['column'].mean()
df['column'].median()
df['column'].mode()
df['column'].var()
df['column'].std()
df['column'].sum()
df['column'].min()
df['column'].max()

ğšğ ğ  ğŸğ®ğ§ğœğ­ğ¢ğ¨ğ§:
df['column'].ğšğ ğ (function_name)

ğšğ ğ  ğŸğ®ğ§ğœğ­ğ¢ğ¨ğ§: allow to pass a fun / list of function to column / list of columns and it will apply the function on them 

df[[list of columns]].agg([ list of fun])
1) Min / max can be used with date column to return older / new 
2)Taking the minimum and maximum of a column of dates is handy for figuring out what time period your data covers. 

ğœğ®ğ¦ğ®ğ¥ğšğ­ğ¢ğ¯ğ ğ¬ğ®ğ¦: 

df['column'].cumsum() 
df['column'].cummin() 
df['column'].cummax()
df['column'].cumprod() 

- each one of them return a record for each row 

cumsum : first_value , v1 + v2 , v1 + v2 + v3 .... sum of all column 
----------------------------------------------------------------------------------------------------------------------------------
ğ¬ğ®ğ¦ğ¦ğšğ«ğ¢ğ³ğ ğœğšğ­ğğ ğ¨ğ«ğ¢ğœğšğ¥ ğğšğ­ğš ğ®ğ¬ğ¢ğ§ğ  ğœğ¨ğ®ğ§ğ­

df.drop_duplicates(subset = 'column_name') >> drop duplcate values in this columns 
df.drop_duplicates(subset = [ "c1" , "c2" ]) 

df['c'].value_counts( sort = True / False ) 
df['c'].value_counts( normalize = True ) #return proportional of total 
var_name = df['c'].value_counts(sort=True, normalize=True)


---------------------------------------------------------
Fill in missing values and sum values with pivot tables
The .pivot_table() method has several useful arguments, including fill_value and margins.

fill_value replaces missing values with a real value (known as imputation). What to replace missing values with is a topic big enough to have its own course (Dealing with Missing Data in Python), but the simplest thing to do is to substitute a dummy value.
margins is a shortcut for when you pivoted by two variables, but also wanted to pivot by each of those variables separately: it gives the row and column totals of the pivot table contents.





-------------------------------------------------------
ğ¬ğğ­ğ­ğ¢ğ§ğ  ğ¢ğ§ğğğ±
df.set_index('column_name') : to make a column as index 


ğ’ğğ­ğ­ğ¢ğ§ğ  ğšğ§ğ ğ«ğğ¦ğ¨ğ¯ğ¢ğ§ğ  ğ¢ğ§ğğğ±ğğ¬

pandas allows you to designate columns as an index. This enables cleaner code when taking subsets (as well as providing more efficient lookup under some circumstances).


The killer feature for indexes is .ğ¥ğ¨ğœ[]: a subsetting method that accepts index values. When you pass it a single argument, it will take a subset of rows.

The code for subsetting using .loc[] can be easier to read than standard square bracket subsetting, which can make your code less burdensome to maintain.

# Make a list of cities to subset on
cities = ["Moscow", "Saint Petersburg"]

# Subset temperatures using square brackets
print(temperatures[temperatures["city"].isin(cities)])

# Subset temperatures_ind using .loc[]
print(temperatures_ind.loc[cities])

Magnificent multi-level indexing! Multi-level indexes can make it easy to comprehend your dataset when one category is nested inside another category.
------------------------------------------------------------------------------------------------------------------------------------------------------------
TO slice the dataframe 
1) first : need to sort it 

df.set_index([list of columns]).sort_index()

-------------------------------------------------------------------------------------------------------------------------------------------------------------
Slicing index values
Slicing lets you select consecutive elements of an object using first:last syntax. DataFrames can be sliced by index values or by row/column number; we'll start with the first case. This involves slicing inside the .loc[] method.

Compared to slicing lists, there are a few things to remember.

You can only slice an index if the index is sorted (using .sort_index()).
To slice at the outer level, first and last can be strings.
To slice at inner levels, first and last should be tuples.
If you pass a single slice to .loc[], it will slice the rows.


Call .sort_index() without arguments.
Slice with code in the form df.loc["a":"b"] twice.
Then slice with code like df.loc[("a", "b"):("c", "d")].


Slice rows with code like df.loc[("a", "b"):("c", "d")].
Slice columns with code like df.loc[:, "e":"f"].
Slice both ways with code like df.loc[("a", "b"):("c", "d"), "e":"f"]



Slicing time series
Slicing is particularly useful for time series since it's a common thing to want to filter for data within a date range.
Add the date column to the index, then use .loc[] to perform the subsetting. The important thing to remember is to keep your dates in ISO 8601 format, 
that is, "yyyy-mm-dd" for year-month-day, "yyyy-mm" for year-month, and "yyyy" for year.

# Use Boolean conditions to subset temperatures for rows in 2010 and 2011
temperatures_bool = temperatures[(temperatures["date"] >= "2010-01-01") & (temperatures["date"] <= "2011-12-31")]
print(temperatures_bool)

# Set date as the index and sort the index
temperatures_ind = temperatures.set_index("date").sort_index()

# Use .loc[] to subset temperatures_ind for rows in 2010 and 2011
print(temperatures_ind.loc["2010":"2011"])

# Use .loc[] to subset temperatures_ind for rows from Aug 2010 to Feb 2011
print(temperatures_ind.loc["2010-08":"2011-02"])




ğšğœğœğğ¬ğ¬ ğ­ğ¡ğ ğœğ¨ğ¦ğ©ğ¨ğ§ğğ§ğ­ğ¬ ğ¨ğŸ ğš ğğšğ­ğ (ğ²ğğšğ«, ğ¦ğ¨ğ§ğ­ğ¡ ğšğ§ğ ğğšğ²) ğ®ğ¬ğ¢ğ§ğ  ğœğ¨ğğ ğ¨ğŸ ğ­ğ¡ğ ğŸğ¨ğ«ğ¦
ğğšğ­ğšğŸğ«ğšğ¦ğ["ğœğ¨ğ¥ğ®ğ¦ğ§"].ğğ­.ğœğ¨ğ¦ğ©ğ¨ğ§ğğ§ğ­. 
ğ…ğ¨ğ« ğğ±ğšğ¦ğ©ğ¥ğ, ğ­ğ¡ğ ğ¦ğ¨ğ§ğ­ğ¡ ğœğ¨ğ¦ğ©ğ¨ğ§ğğ§ğ­ ğ¢ğ¬
> ğğšğ­ğšğŸğ«ğšğ¦ğ["ğœğ¨ğ¥ğ®ğ¦ğ§"].ğğ­.ğ¦ğ¨ğ§ğ­ğ¡, 
ğšğ§ğ ğ­ğ¡ğ ğ²ğğšğ« ğœğ¨ğ¦ğ©ğ¨ğ§ğğ§ğ­ ğ¢ğ¬ 
ğğšğ­ğšğŸğ«ğšğ¦ğ["ğœğ¨ğ¥ğ®ğ¦ğ§"].ğğ­.ğ²ğğšğ«.



Insightful use of .iloc[]! Use .iloc[] to specify a subset using the row or column numbers.

Subsetting pivot tables
A pivot table is just a DataFrame with sorted indexes, so the techniques you have learned already can be used to subset them. In particular, the .loc[] + slicing combination is often helpful.




Calculating on a pivot table
Pivot tables are filled with summary statistics, but they are only a first step to finding something insightful. 
Often you'll need to perform further calculations on them. 






Calculate the mean temperature for each year, assigning to mean_temp_by_year.
Filter mean_temp_by_year for the year that had the highest mean temperature.
Calculate the mean temperature for each city (across columns), assigning to mean_temp_by_city.
Filter mean_temp_by_city for the city that had the lowest mean temperature.

hints
Call .mean() without arguments to get the mean of each column.
Use Boolean filtering of the form mean_temp_by_year equal to mean_temp_by_year.max().
Call .mean(), setting axis to "columns" to get the mean of each row.
Use Boolean filtering of the form mean_temp_by_city equal to mean_temp_by_city.min().
A common thing to do is to find the rows or columns where the highest or lowest value occurs.



# Get the worldwide mean temp by year
mean_temp_by_year = temp_by_country_city_vs_year.mean()

# Filter for the year that had the highest mean temp
print(mean_temp_by_year[mean_temp_by_year == mean_temp_by_year.max()])

# Get the mean temp by city
mean_temp_by_city = temp_by_country_city_vs_year.mean(axis="columns")

# Filter for the city that had the lowest mean temp
print(mean_temp_by_city[mean_temp_by_city == mean_temp_by_city.min()])
-----------------------------------------------------------------------------------------
ğ•ğ¢ğ¬ğ®ğšğ¥ğ¢ğ³ğ¢ğ§ğ  ğ²ğ¨ğ®ğ« ğğšğ­ğš

import matplotlib..pyplot as plt 


df['column'].hist()
plt.show()

for categorical columns 
1) x - axis : values of categorical
2) y-axis : counting of values for each category 
